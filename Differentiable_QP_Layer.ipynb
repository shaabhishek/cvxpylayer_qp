{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeMarzaY8ixZwoHF/f8B3l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaabhishek/cvxpylayer_qp/blob/main/Differentiable_QP_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cvxpylayers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXZt5TTXjqYw",
        "outputId": "f0604b9a-1ed3-45eb-ea09-a94729a2a115"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cvxpylayers in /usr/local/lib/python3.8/dist-packages (0.1.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from cvxpylayers) (1.7.3)\n",
            "Requirement already satisfied: cvxpy>=1.1.0a4 in /usr/local/lib/python3.8/dist-packages (from cvxpylayers) (1.2.3)\n",
            "Requirement already satisfied: diffcp>=1.0.13 in /usr/local/lib/python3.8/dist-packages (from cvxpylayers) (1.0.21)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from cvxpylayers) (1.22.4)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers) (0.6.2.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers) (2.0.12)\n",
            "Requirement already satisfied: setuptools<=64.0.2 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers) (57.4.0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.1.0a4->cvxpylayers) (3.2.2)\n",
            "Requirement already satisfied: pybind11>=2.4 in /usr/local/lib/python3.8/dist-packages (from diffcp>=1.0.13->cvxpylayers) (2.10.3)\n",
            "Requirement already satisfied: threadpoolctl>=1.1 in /usr/local/lib/python3.8/dist-packages (from diffcp>=1.0.13->cvxpylayers) (3.1.0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.8/dist-packages (from osqp>=0.4.1->cvxpy>=1.1.0a4->cvxpylayers) (0.1.5.post3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lMmPu_UsI9CI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import scipy\n",
        "import cvxpy as cvx\n",
        "import jax\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "import jax.numpy as jnp\n",
        "from cvxpylayers.jax import CvxpyLayer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = jnp.diag\n",
        "ccat = lambda x: jnp.concatenate(x, axis=1)\n",
        "rcat = lambda x: jnp.concatenate(x, axis=0)\n",
        "mv = lambda A,b: jnp.einsum(\"ij,j->i\", A, b)\n",
        "outer = jnp.outer\n",
        "\n",
        "def make_problem_cvxpy(n_vars, n_eq, n_ineq):\n",
        "    # Create a CVXPY problem.\n",
        "    z = cvx.Variable(n_vars)\n",
        "\n",
        "    L = cvx.Parameter((n_vars, n_vars))\n",
        "    c = cvx.Parameter((n_vars))\n",
        "    A = cvx.Parameter((n_eq, n_vars))\n",
        "    b = cvx.Parameter((n_eq))\n",
        "    G = cvx.Parameter((n_ineq, n_vars))\n",
        "    h = cvx.Parameter((n_ineq))\n",
        "\n",
        "    objective = cvx.Minimize( 0.5 * cvx.sum_squares(L @ z) + c @ z)\n",
        "    # objective = cvx.Minimize( c @ z)\n",
        "    constraints = [A @ z == b, G @ z <= h]\n",
        "    prob = cvx.Problem(objective, constraints)\n",
        "    assert prob.is_dpp()\n",
        "    return prob, z, constraints, [L, c, A, b, G, h]\n",
        "\n",
        "def make_problem_cvxpy_batch(n_vars, n_eq, n_ineq, n_batch):\n",
        "    # Create a CVXPY problem.\n",
        "    z = cvx.Variable((n_batch, n_vars))\n",
        "\n",
        "    L = cvx.Parameter((n_batch, n_vars, n_vars))\n",
        "    c = cvx.Parameter((n_batch, n_vars))\n",
        "    A = cvx.Parameter((n_batch, n_eq, n_vars))\n",
        "    b = cvx.Parameter((n_batch, n_eq))\n",
        "    G = cvx.Parameter((n_batch, n_ineq, n_vars))\n",
        "    h = cvx.Parameter((n_batch, n_ineq))\n",
        "\n",
        "    # objective = cvx.Minimize( 0.5 * cvx.sum_squares(L @ z) + c @ z)\n",
        "    cost = 0\n",
        "    for i in range(n_batch):\n",
        "        cost += 0.5 * cvx.sum_squares(L[i] @ z[i]) + c[i] @ z[i]\n",
        "    objective = cvx.Minimize(cost)\n",
        "\n",
        "    constraints = []\n",
        "    for i in range(n_batch):\n",
        "        constraints.append(A[i] @ z[i] == b[i])\n",
        "\n",
        "    for i in range(n_batch):\n",
        "        constraints.append(G[i] @ z[i] <= h[i])\n",
        "\n",
        "    prob = cvx.Problem(objective, constraints)\n",
        "    assert prob.is_dpp()\n",
        "    return prob, z, constraints, [L, c, A, b, G, h]\n",
        "\n",
        "def solve_problem_cvxpy(prob, x, constraints, params, data):\n",
        "    for p, d in zip(params, data):\n",
        "        p.value = np.array(d)\n",
        "\n",
        "    prob.solve(solver=cvx.SCS, verbose=False, warm_start=True, eps=1e-6)\n",
        "    return x.value, constraints[0].dual_value, constraints[1].dual_value\n",
        "\n",
        "def make_problem_cvxpylayer(prob, x, params):\n",
        "    cvxpylayer = CvxpyLayer(prob, parameters=params, variables=[x])\n",
        "    return cvxpylayer\n",
        "\n",
        "def solve_problem_cvxpylayer(cvxpylayer, data):\n",
        "    return cvxpylayer(*data, solver_args={\"eps\": 1e-6})\n",
        "\n",
        "@jax.jit\n",
        "def compute_grads_manual(z_star, nu_star, lambda_star, data, grad_l):\n",
        "    (L, c, A, b, G, h) = data\n",
        "    Q = L @ L.T\n",
        "    \n",
        "    M = rcat(\n",
        "        [\n",
        "            ccat([Q, G.T, A.T]),\n",
        "            ccat([D(lambda_star)@G, D(mv(G, z_star) - h), jnp.zeros((n_ineq,n_eq))]),\n",
        "            ccat([A, jnp.zeros((n_eq,n_ineq)), jnp.zeros((n_eq,n_eq))])\n",
        "            ])\n",
        "    \n",
        "    assert M.shape == (n_vars+n_eq+n_ineq, n_vars+n_eq+n_ineq)\n",
        "\n",
        "    eq_37 = -jnp.linalg.solve( M.T, grad_l )\n",
        "    d_z, d_lambda, d_nu = eq_37[:n_vars], eq_37[n_vars:n_vars+n_ineq], eq_37[n_vars+n_ineq:]\n",
        "    \n",
        "    grad_L = L @ (outer(d_z, z_star) + outer(z_star, d_z))\n",
        "    grad_c = d_z\n",
        "    grad_A = outer(d_nu, z_star) + outer(nu_star, d_z)\n",
        "    grad_b = -d_nu\n",
        "    grad_G = outer(lambda_star, d_z) + D(lambda_star) @ outer(d_lambda, z_star)\n",
        "    grad_h = -mv(D(lambda_star), d_lambda)\n",
        "    return grad_L, grad_c, grad_A, grad_b, grad_G, grad_h\n"
      ],
      "metadata": {
        "id": "oR8bxc98NIOS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create data (i.e. parameters Q, c, A, b, G, h)"
      ],
      "metadata": {
        "id": "FvWn8jctdLWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(n_vars, n_eq, n_ineq):\n",
        "    Q = np.random.randn(n_vars, n_vars)\n",
        "    # Q = np.zeros((n_vars, n_vars))\n",
        "    Q = Q@Q.T\n",
        "    assert np.all(np.linalg.eigvals(Q) >= 0)\n",
        "\n",
        "    # L = np.linalg.cholesky(Q)\n",
        "    L = scipy.linalg.sqrtm(Q)\n",
        "    assert np.allclose(Q, L@L.T)\n",
        "    c = np.random.randn(n_vars)\n",
        "    A = np.random.randn(n_eq, n_vars)\n",
        "    b = np.random.randn(n_eq)\n",
        "    # G = np.random.randn(n_ineq, n_vars)\n",
        "    # h = np.random.randn(n_ineq)\n",
        "\n",
        "    G = np.eye(n_vars)\n",
        "    h = np.zeros(n_vars)\n",
        "    return (L, c, A, b, G, h)\n",
        "\n",
        "def get_data_batch(n_vars, n_eq, n_ineq, n_batch):\n",
        "    Q = np.random.randn(n_batch, n_vars, n_vars)\n",
        "    Q = np.einsum(\"bij,bkj->bik\", Q, Q)\n",
        "    assert np.all(np.linalg.eigvals(Q[0]) >= 0)\n",
        "    L = np.stack([scipy.linalg.sqrtm(_Q) for _Q in Q], axis=0)\n",
        "\n",
        "    c = np.random.randn(n_batch, n_vars)\n",
        "    A = np.random.randn(n_batch, n_eq, n_vars)\n",
        "    b = np.random.randn(n_batch, n_eq)\n",
        "    # G = np.random.randn(n_batch, n_ineq, n_vars)\n",
        "    # h = np.random.randn(n_batch, n_ineq)\n",
        "\n",
        "    G = np.stack([np.eye(n_vars) for _ in range(n_batch)], axis=0)\n",
        "    h = np.zeros((n_batch, n_vars))\n",
        "\n",
        "    return (L, c, A, b, G, h)"
      ],
      "metadata": {
        "id": "WD6frbv7dQfh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l_cvxpylayer(data, prob, x, params):\n",
        "    cvxpylayer = make_problem_cvxpylayer(prob, x, params)\n",
        "    z_star_layer, = solve_problem_cvxpylayer(cvxpylayer, data)\n",
        "    return jnp.sum(z_star_layer), z_star_layer\n",
        "\n",
        "def l_manual(data, prob, x, constraints, params):\n",
        "    z_star, nu_star, lambda_star = solve_problem_cvxpy(prob, x, constraints, params, data)\n",
        "    # print(z_star, nu_star, lambda_star)\n",
        "    # print(lambda_star)\n",
        "    grad_l = jnp.concatenate([jnp.ones_like(z_star), jnp.zeros_like(lambda_star), jnp.zeros_like(nu_star)])\n",
        "    grads_manual = compute_grads_manual(z_star, nu_star, lambda_star, data, grad_l)\n",
        "    l = z_star.sum()\n",
        "    return (l, z_star), grads_manual\n",
        "\n",
        "\n",
        "n_vars = 60\n",
        "n_eq = 10\n",
        "n_ineq = n_vars\n",
        "data = get_data(n_vars, n_eq, n_ineq)\n",
        "data_batch = get_data_batch(n_vars, n_eq, n_ineq, 20)\n",
        "prob, x, constraints, params = make_problem_cvxpy(n_vars, n_eq, n_ineq)\n",
        "\n",
        "l_cvxpylayer_value_and_grad = jax.value_and_grad(l_cvxpylayer, has_aux=True)\n",
        "(_, z_star_layer), grads_cvxpylayers = l_cvxpylayer_value_and_grad(data, prob, x, params)\n",
        "(_, z_star), grads_manual = l_manual(data, prob, x, constraints, params)\n",
        "l_cvxpylayer_value_and_grad(data_batch, prob, x, params)\n"
      ],
      "metadata": {
        "id": "9VKL7HtBJDYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare solutions"
      ],
      "metadata": {
        "id": "ia3FXjxgdHgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(z_star)\n",
        "print(z_star_layer)\n",
        "\n",
        "assert np.allclose(z_star, z_star_layer, atol=1e-3), np.sum(np.abs(z_star - z_star_layer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBUbdN4vSzq5",
        "outputId": "bdb3c837-abe8-4ef4-d64f-4a6585edbe30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.92095910e-07 -9.03358617e-09 -3.02948103e-02 -5.77438299e-02\n",
            " -3.78558184e-06 -1.40480123e-06  6.35821865e-07  2.40269849e-06\n",
            " -3.37088648e-06 -2.87031143e-01  1.44705499e-06 -3.64549815e-06\n",
            " -1.34774959e-01 -4.66068713e-08 -2.05358857e-01 -3.52979741e-07\n",
            "  3.14795604e-07 -4.74028675e-06  2.05294454e-06 -2.23238890e-06\n",
            " -1.66936156e-06  8.31118822e-07 -6.62853057e-02 -6.08125066e-02\n",
            " -2.94993391e-07 -2.65497135e-06  1.80870588e-06 -1.69735501e-07\n",
            " -1.56534947e-02  5.52173548e-07 -1.47002980e-01 -1.90311851e-01\n",
            " -1.02680867e-06 -6.70239021e-02 -1.95052416e-06 -2.50558895e-01\n",
            " -2.02113804e-06  1.13746806e-07 -1.73954006e-06 -1.36995157e-01\n",
            " -8.80179502e-02 -8.54248521e-04  1.45600071e-06 -4.50688332e-02\n",
            " -1.99705499e-01 -1.27820008e-01 -8.45903139e-02 -1.06381958e-06\n",
            " -1.11386409e-06 -1.47207936e-06 -2.86520682e-06 -5.60403558e-02\n",
            "  8.77500607e-07 -1.72418224e-02 -1.64619940e-01 -1.90040470e-01\n",
            "  2.44866859e-06 -2.27321116e-06 -9.77023309e-02 -1.72196622e-01]\n",
            "[-4.92095547e-07 -9.03345204e-09 -3.02948103e-02 -5.77438299e-02\n",
            " -3.78558149e-06 -1.40480125e-06  6.35822473e-07  2.40269874e-06\n",
            " -3.37088645e-06 -2.87031143e-01  1.44705521e-06 -3.64549795e-06\n",
            " -1.34774959e-01 -4.66063857e-08 -2.05358857e-01 -3.52979573e-07\n",
            "  3.14795890e-07 -4.74028667e-06  2.05294555e-06 -2.23238903e-06\n",
            " -1.66936113e-06  8.31119326e-07 -6.62853057e-02 -6.08125066e-02\n",
            " -2.94992529e-07 -2.65497101e-06  1.80870575e-06 -1.69735527e-07\n",
            " -1.56534947e-02  5.52173669e-07 -1.47002980e-01 -1.90311851e-01\n",
            " -1.02680810e-06 -6.70239021e-02 -1.95052405e-06 -2.50558895e-01\n",
            " -2.02113806e-06  1.13746823e-07 -1.73953969e-06 -1.36995157e-01\n",
            " -8.80179502e-02 -8.54248521e-04  1.45600131e-06 -4.50688332e-02\n",
            " -1.99705499e-01 -1.27820008e-01 -8.45903139e-02 -1.06381936e-06\n",
            " -1.11386398e-06 -1.47207916e-06 -2.86520664e-06 -5.60403558e-02\n",
            "  8.77500916e-07 -1.72418224e-02 -1.64619940e-01 -1.90040470e-01\n",
            "  2.44866882e-06 -2.27321051e-06 -9.77023309e-02 -1.72196622e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling Code"
      ],
      "metadata": {
        "id": "-arG47O_cqIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 5 (_, z_star), grads_manual = l_manual(data, prob, x, constraints, params)\n",
        "# %timeit -n 5 (_, z_star_layer), grads_cvxpylayers = l_cvxpylayer_value_and_grad(data, prob, x, params)\n",
        "# %timeit -n 5 [l_manual(_data, prob, x, constraints, params) for _data in zip(*data_batch)]\n",
        "# %timeit -n 5 (_, z_star_layer), grads_cvxpylayers = l_cvxpylayer_value_and_grad(data_batch, prob, x, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNILF12KsuHJ",
        "outputId": "8b52c720-fb4e-4ce6-c3f5-ce54b062901f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "941 ms ± 93.7 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n",
            "765 ms ± 89.2 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Gradients"
      ],
      "metadata": {
        "id": "2cClaGATc1Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import lru_cache\n",
        "# Test gradients\n",
        "eps = 1e-2\n",
        "\n",
        "def f_c(_c):\n",
        "    (L, c, A, b, G, h) = data\n",
        "    data_new = (L, _c, A, b, G, h)\n",
        "    return l_manual(data_new, prob, x, constraints, params)[0][0]\n",
        "\n",
        "def f_b(_b):\n",
        "    (L, c, A, b, G, h) = data\n",
        "    data_new = (L, c, A, _b, G, h)\n",
        "    return l_manual(data_new, prob, x, constraints, params)[0][0]\n",
        "\n",
        "def f_h(_h):\n",
        "    (L, c, A, b, G, h) = data\n",
        "    data_new = (L, c, A, b, G, _h)\n",
        "    return l_manual(data_new, prob, x, constraints, params)[0][0]\n",
        "\n",
        "def f_G(_G):\n",
        "    (L, c, A, b, G, h) = data\n",
        "    data_new = (L, c, A, b, _G, h)\n",
        "    return l_manual(data_new, prob, x, constraints, params)[0][0]\n",
        "\n",
        "# c\n",
        "# print(grads_manual[1].round(3))\n",
        "# print(grads_cvxpylayers[1].round(3))\n",
        "# print(np.array([((f_c(data[1]+h_c) - f_c(data[1]-h_c)) / (2*h_c + 1e-6))[i] for i, h_c in enumerate(np.eye(n_vars)*eps)]).round(3))\n",
        "# print()\n",
        "\n",
        "# b\n",
        "# print(grads_manual[3].round(3))\n",
        "# print(grads_cvxpylayers[3].round(3))\n",
        "# print(np.array([((f_b(data[3]+h_b) - f_b(data[3]-h_b)) / (2*h_b + 1e-10))[i] for i, h_b in enumerate(np.eye(n_eq)*eps)]).round(3))\n",
        "# print()\n",
        "\n",
        "# h\n",
        "# print(grads_manual[5].round(3))\n",
        "# print(grads_cvxpylayers[5].round(3))\n",
        "# print(np.array([((f_h(data[5]+h_h) - f_h(data[5]-h_h)) / (2*h_h + 1e-10))[i] for i, h_h in enumerate(np.eye(n_ineq)*eps)]).round(3))\n",
        "\n",
        "# G\n",
        "i = 1\n",
        "print(grads_manual[4][i].round(3))\n",
        "print(grads_cvxpylayers[4][i].round(3))\n",
        "\n",
        "@lru_cache(maxsize=n_vars*n_ineq)\n",
        "def make_h_G(i,j):\n",
        "    h_G = np.zeros_like(data[4])\n",
        "    h_G[i,j]+=eps\n",
        "    return h_G\n",
        "\n",
        "row = [((f_G(data[4]+make_h_G(i,j)) - f_G(data[4]-make_h_G(i,j))) / (2*make_h_G(i,j) + 1e-10))[i,j] for j in range(data[4].shape[1])]\n",
        "print(np.array(row).round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UoZDEm6tLbk",
        "outputId": "8f812b81-b275-459c-b504-c8601e8827ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.     0.    -0.523 -0.144 -0.    -0.    -0.    -0.    -0.     0.461\n",
            " -0.    -0.     0.432 -0.     0.187 -0.    -0.    -0.    -0.    -0.\n",
            "  0.    -0.     0.394 -0.022  0.     0.     0.    -0.     0.145  0.\n",
            "  0.389  0.644 -0.    -0.009 -0.     0.548 -0.     0.    -0.    -0.405\n",
            " -0.447 -0.579 -0.    -0.693  0.723  0.201 -0.444 -0.    -0.     0.\n",
            "  0.    -0.6   -0.    -0.517  0.573  0.666  0.     0.    -0.434 -0.007]\n",
            "[-0.141  0.038 -1.103 -0.016 -0.053 -0.394  0.307  0.045 -0.024  0.305\n",
            " -0.097  0.188 -0.024 -0.201  0.49  -0.459 -0.219  0.089 -0.301 -0.58\n",
            "  0.19  -0.06   0.463 -0.178  0.143  0.133 -0.22  -0.017 -0.359 -0.095\n",
            "  0.445  0.19  -0.154  0.202  0.055  0.336 -0.243 -0.292 -0.204 -0.158\n",
            " -0.389 -1.023  0.492 -1.097  1.013  0.146 -0.421 -0.163 -0.17  -0.03\n",
            "  0.034 -1.238 -0.154 -1.056  0.907  0.657 -0.255  0.033 -0.734  0.132]\n",
            "[-0.    -0.001 -0.52  -0.145 -0.003  0.     0.     0.002 -0.003  0.461\n",
            " -0.002 -0.001  0.434  0.003  0.187 -0.002  0.    -0.001  0.001  0.\n",
            " -0.    -0.     0.38  -0.023 -0.004 -0.001 -0.004  0.002  0.145 -0.\n",
            "  0.37   0.644 -0.003 -0.011  0.     0.549 -0.001 -0.001  0.    -0.407\n",
            " -0.445 -0.378  0.001 -0.693  0.671  0.2   -0.443 -0.004 -0.001 -0.\n",
            "  0.    -0.598 -0.001 -0.519  0.573  0.666  0.002 -0.001 -0.427 -0.006]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([g.shape for g in grads_manual])\n",
        "print([g.shape for g in grads_cvxpylayers])\n",
        "print(*[g.round(4) for g in grads_manual], sep='\\n')\n",
        "print()\n",
        "print(*[g.round(4) for g in grads_cvxpylayers], sep='\\n')\n",
        "\n",
        "print(*[np.sum(g1-g2) for g1,g2 in zip(grads_manual, grads_cvxpylayers)], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgniumQpR2x",
        "outputId": "0ffee7a2-b463-4d19-d1fd-2250dfd7776b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(60, 60), (60,), (10, 60), (10,), (60, 60), (60,)]\n",
            "[(60, 60), (60,), (10, 60), (10,), (60, 60), (60,)]\n",
            "[[ 0.      0.      0.0156 ...  0.      0.0191  0.0147]\n",
            " [-0.     -0.      0.0044 ... -0.     -0.0005 -0.0097]\n",
            " [ 0.      0.     -0.0004 ...  0.      0.0095  0.0232]\n",
            " ...\n",
            " [ 0.      0.     -0.0055 ...  0.     -0.0043  0.0006]\n",
            " [ 0.      0.      0.0199 ...  0.      0.0305  0.0333]\n",
            " [ 0.      0.      0.0263 ...  0.      0.0335  0.028 ]]\n",
            "[-0.     -0.     -0.032  -0.0156 -0.     -0.      0.      0.     -0.\n",
            " -0.015   0.     -0.      0.0044 -0.     -0.0184 -0.      0.     -0.\n",
            "  0.     -0.      0.      0.      0.0118 -0.0096 -0.     -0.      0.\n",
            " -0.      0.0056  0.      0.0004  0.008  -0.     -0.0097 -0.     -0.0054\n",
            " -0.      0.     -0.     -0.0404 -0.0359 -0.0309  0.     -0.043   0.0109\n",
            " -0.0069 -0.0352 -0.     -0.     -0.     -0.     -0.0396  0.     -0.0299\n",
            "  0.0078  0.0092  0.     -0.     -0.0365 -0.0241]\n",
            "[[ 0.     -0.     -0.2172 -0.0653 -0.     -0.     -0.     -0.     -0.\n",
            "   0.1568 -0.     -0.      0.1617 -0.      0.0536 -0.      0.     -0.\n",
            "  -0.     -0.      0.     -0.      0.1538 -0.0158  0.      0.      0.\n",
            "  -0.      0.0576  0.      0.1427  0.2421 -0.     -0.011  -0.      0.1964\n",
            "  -0.      0.     -0.     -0.1806 -0.1924 -0.2366 -0.     -0.288   0.2732\n",
            "   0.068  -0.1906 -0.     -0.      0.      0.     -0.2515 -0.     -0.2131\n",
            "   0.216   0.251   0.     -0.     -0.188  -0.0218]\n",
            " [ 0.      0.      0.1537  0.0556  0.      0.     -0.     -0.      0.\n",
            "  -0.0512 -0.      0.     -0.084   0.      0.0032  0.     -0.      0.\n",
            "  -0.      0.     -0.     -0.     -0.0918  0.0225 -0.     -0.     -0.\n",
            "   0.     -0.0362 -0.     -0.0687 -0.128   0.      0.0204  0.     -0.0852\n",
            "   0.     -0.      0.      0.1494  0.148   0.1612  0.      0.2047 -0.1474\n",
            "  -0.0216  0.1461  0.      0.      0.      0.      0.182  -0.      0.1484\n",
            "  -0.1152 -0.1341 -0.      0.      0.1469  0.0481]\n",
            " [-0.     -0.     -0.097  -0.0311 -0.     -0.      0.     -0.     -0.\n",
            "   0.0579 -0.     -0.      0.066  -0.      0.0156 -0.      0.     -0.\n",
            "  -0.     -0.      0.     -0.      0.0652 -0.0094  0.      0.      0.\n",
            "  -0.      0.0248  0.      0.0572  0.0993 -0.     -0.0075 -0.      0.0768\n",
            "  -0.      0.     -0.     -0.085  -0.0883 -0.1044 -0.     -0.1288  0.1127\n",
            "   0.025  -0.0874 -0.     -0.     -0.      0.     -0.1131 -0.     -0.0946\n",
            "   0.0888  0.1033  0.     -0.     -0.0868 -0.0164]\n",
            " [ 0.      0.      0.1529  0.0483  0.      0.     -0.      0.      0.\n",
            "  -0.0954  0.      0.     -0.1062  0.     -0.0275  0.     -0.      0.\n",
            "   0.      0.     -0.      0.     -0.104   0.014  -0.     -0.     -0.\n",
            "   0.     -0.0394 -0.     -0.0924 -0.1596  0.      0.0109  0.     -0.1248\n",
            "   0.     -0.      0.      0.1325  0.1384  0.165   0.      0.2029 -0.1808\n",
            "  -0.0412  0.137   0.      0.      0.     -0.      0.178   0.      0.1494\n",
            "  -0.1426 -0.1658 -0.      0.      0.1358  0.0235]\n",
            " [-0.     -0.     -0.2561 -0.0902 -0.     -0.      0.      0.     -0.\n",
            "   0.1012  0.     -0.      0.1481 -0.      0.0056 -0.      0.     -0.\n",
            "   0.     -0.      0.      0.      0.1575 -0.0345  0.      0.      0.\n",
            "  -0.      0.0615  0.      0.1231  0.2248 -0.     -0.0307 -0.      0.1563\n",
            "  -0.      0.     -0.     -0.2431 -0.2434 -0.2702 -0.     -0.3408  0.2577\n",
            "   0.043  -0.2404 -0.     -0.     -0.     -0.     -0.3021  0.     -0.2478\n",
            "   0.2019  0.235   0.     -0.     -0.241  -0.0715]\n",
            " [-0.     -0.     -0.1118 -0.0473 -0.     -0.      0.      0.     -0.\n",
            "  -0.0063  0.     -0.      0.0389 -0.     -0.0323 -0.      0.     -0.\n",
            "   0.     -0.      0.      0.      0.0544 -0.0246 -0.     -0.      0.\n",
            "  -0.      0.023   0.      0.0265  0.0615 -0.     -0.0241 -0.      0.0228\n",
            "  -0.      0.     -0.     -0.1244 -0.1163 -0.1127  0.     -0.1496  0.0737\n",
            "  -0.0037 -0.1145 -0.     -0.     -0.     -0.     -0.1354  0.     -0.1062\n",
            "   0.0564  0.0658  0.     -0.     -0.1169 -0.0588]\n",
            " [ 0.      0.      0.2661  0.1139  0.      0.     -0.     -0.      0.\n",
            "   0.0227 -0.      0.     -0.0887  0.      0.0823  0.     -0.      0.\n",
            "  -0.      0.     -0.     -0.     -0.1273  0.0601  0.      0.     -0.\n",
            "   0.     -0.0541 -0.     -0.0588 -0.1408  0.      0.059   0.     -0.0473\n",
            "   0.     -0.      0.      0.2989  0.2782  0.2675 -0.      0.3562 -0.1693\n",
            "   0.0122  0.2739  0.      0.      0.      0.      0.3226 -0.      0.2523\n",
            "  -0.1292 -0.151  -0.      0.      0.28    0.1443]\n",
            " [-0.     -0.     -0.0093 -0.0042 -0.     -0.      0.      0.     -0.\n",
            "  -0.0022  0.     -0.      0.0024 -0.     -0.0038 -0.      0.     -0.\n",
            "   0.     -0.      0.      0.      0.0041 -0.0024 -0.     -0.      0.\n",
            "  -0.      0.0018  0.      0.0013  0.0039 -0.     -0.0024 -0.      0.0004\n",
            "  -0.      0.     -0.     -0.011  -0.01   -0.0092  0.     -0.0125  0.0049\n",
            "  -0.001  -0.0099 -0.     -0.     -0.     -0.     -0.0114  0.     -0.0088\n",
            "   0.0037  0.0043  0.     -0.     -0.0101 -0.0058]\n",
            " [-0.     -0.     -0.0719 -0.0357 -0.     -0.      0.      0.     -0.\n",
            "  -0.0378  0.     -0.      0.0078 -0.     -0.044  -0.      0.     -0.\n",
            "   0.     -0.      0.      0.      0.0254 -0.0222 -0.     -0.      0.\n",
            "  -0.      0.0122  0.     -0.0012  0.0151 -0.     -0.0226 -0.     -0.0157\n",
            "  -0.      0.     -0.     -0.0922 -0.0814 -0.069   0.     -0.0967  0.0214\n",
            "  -0.0174 -0.0799 -0.     -0.     -0.     -0.     -0.0893  0.     -0.0669\n",
            "   0.015   0.0177  0.     -0.     -0.083  -0.0563]\n",
            " [ 0.      0.      0.0362  0.016   0.      0.     -0.     -0.      0.\n",
            "   0.0065 -0.      0.     -0.0103  0.      0.0136  0.     -0.      0.\n",
            "  -0.      0.     -0.     -0.     -0.0163  0.0088  0.      0.     -0.\n",
            "   0.     -0.0071 -0.     -0.0061 -0.0167  0.      0.0088  0.     -0.0033\n",
            "   0.     -0.      0.      0.0419  0.0385  0.036  -0.      0.0485 -0.0204\n",
            "   0.0032  0.0379  0.      0.      0.      0.      0.0441 -0.      0.0342\n",
            "  -0.0154 -0.018  -0.      0.      0.0389  0.0215]]\n",
            "[ 0.9481 -0.4521  0.3789 -0.6126  0.8112  0.1692 -0.3741  0.008  -0.0149\n",
            " -0.0383]\n",
            "[[-0.     -0.     -0.6586 ... -0.     -0.5734 -0.0739]\n",
            " [ 0.      0.     -0.5234 ...  0.     -0.4337 -0.0067]\n",
            " [ 0.      0.      0.     ...  0.      0.      0.    ]\n",
            " ...\n",
            " [ 0.     -0.     -0.6338 ...  0.     -0.5399 -0.0429]\n",
            " [ 0.      0.      0.     ...  0.      0.      0.    ]\n",
            " [ 0.      0.      0.     ...  0.      0.      0.    ]]\n",
            "[ 2.8213  2.5907 -0.     -0.      3.5378  3.9578  2.972   1.4925  3.0832\n",
            " -0.      1.1091  1.681  -0.      3.9363 -0.      2.4693  3.8053  1.247\n",
            "  3.6748  3.3842 -0.4036  1.9961 -0.     -0.      2.9274  1.3141  1.2773\n",
            "  1.1721 -0.      2.6972 -0.     -0.      3.8319 -0.      2.2062 -0.\n",
            "  1.4269  1.2251  3.9479 -0.     -0.     -0.      1.2621 -0.     -0.\n",
            " -0.     -0.      1.8615  0.9371  3.8887  1.8488 -0.      0.5439  0.\n",
            " -0.     -0.      1.9752  2.9044 -0.     -0.    ]\n",
            "\n",
            "[[ 0.0035 -0.0009  0.0302 ... -0.0008  0.0268  0.0116]\n",
            " [ 0.0016 -0.0004  0.0099 ... -0.0004 -0.001  -0.0184]\n",
            " [-0.0012  0.0003 -0.0037 ...  0.0003  0.0121  0.0336]\n",
            " ...\n",
            " [-0.0015  0.0004 -0.011  ...  0.0004 -0.0053  0.0059]\n",
            " [ 0.0038 -0.001   0.0366 ... -0.0009  0.0421  0.0359]\n",
            " [ 0.0058 -0.0015  0.0493 ... -0.0014  0.0436  0.0186]]\n",
            "[-0.0075  0.002  -0.0648 -0.0126 -0.0028 -0.021   0.0163  0.0024 -0.0013\n",
            " -0.0423 -0.0051  0.01   -0.0287 -0.0107 -0.0158 -0.0244 -0.0116  0.0047\n",
            " -0.016  -0.0308  0.0101 -0.0032  0.0111 -0.0219  0.0076  0.0071 -0.0117\n",
            " -0.0009 -0.0223 -0.005  -0.0063 -0.0287 -0.0082 -0.0029  0.0029 -0.0332\n",
            " -0.0129 -0.0155 -0.0109 -0.0363 -0.0386 -0.0546  0.0261 -0.0675  0.0132\n",
            " -0.0183 -0.0396 -0.0087 -0.009  -0.0016  0.0018 -0.0772 -0.0082 -0.0596\n",
            "  0.0147 -0.0038 -0.0135  0.0018 -0.059  -0.0281]\n",
            "[[-5.780e-02  1.540e-02 -4.704e-01 -4.400e-02 -2.150e-02 -1.611e-01\n",
            "   1.254e-01  1.860e-02 -1.000e-02 -6.180e-02 -3.950e-02  7.680e-02\n",
            "  -9.730e-02 -8.230e-02  6.670e-02 -1.875e-01 -8.940e-02  3.630e-02\n",
            "  -1.230e-01 -2.369e-01  7.750e-02 -2.450e-02  1.462e-01 -1.123e-01\n",
            "   5.830e-02  5.450e-02 -9.000e-02 -7.100e-03 -1.569e-01 -3.870e-02\n",
            "   8.640e-02 -4.570e-02 -6.270e-02  3.910e-02  2.240e-02 -2.530e-02\n",
            "  -9.930e-02 -1.192e-01 -8.360e-02 -1.536e-01 -2.161e-01 -4.185e-01\n",
            "   2.009e-01 -4.775e-01  2.844e-01 -2.340e-02 -2.271e-01 -6.650e-02\n",
            "  -6.930e-02 -1.250e-02  1.400e-02 -5.422e-01 -6.300e-02 -4.426e-01\n",
            "   2.638e-01  1.451e-01 -1.041e-01  1.350e-02 -3.636e-01 -5.770e-02]\n",
            " [ 3.930e-02 -1.050e-02  3.141e-01  1.830e-02  1.470e-02  1.096e-01\n",
            "  -8.530e-02 -1.260e-02  6.800e-03 -1.590e-02  2.690e-02 -5.230e-02\n",
            "   3.900e-02  5.600e-02 -8.680e-02  1.276e-01  6.090e-02 -2.470e-02\n",
            "   8.370e-02  1.612e-01 -5.270e-02  1.670e-02 -1.128e-01  6.420e-02\n",
            "  -3.970e-02 -3.710e-02  6.120e-02  4.800e-03  1.036e-01  2.630e-02\n",
            "  -8.840e-02 -7.300e-03  4.270e-02 -4.010e-02 -1.530e-02 -3.330e-02\n",
            "   6.760e-02  8.110e-02  5.690e-02  7.690e-02  1.293e-01  2.847e-01\n",
            "  -1.367e-01  3.159e-01 -2.338e-01 -9.800e-03  1.375e-01  4.530e-02\n",
            "   4.720e-02  8.500e-03 -9.600e-03  3.577e-01  4.290e-02  2.977e-01\n",
            "  -2.128e-01 -1.371e-01  7.080e-02 -9.200e-03  2.277e-01  4.500e-03]\n",
            " [-2.550e-02  6.800e-03 -2.162e-01 -3.600e-02 -9.500e-03 -7.100e-02\n",
            "   5.530e-02  8.200e-03 -4.400e-03 -1.098e-01 -1.740e-02  3.390e-02\n",
            "  -8.170e-02 -3.630e-02 -2.970e-02 -8.270e-02 -3.940e-02  1.600e-02\n",
            "  -5.420e-02 -1.045e-01  3.420e-02 -1.080e-02  4.540e-02 -6.700e-02\n",
            "   2.570e-02  2.400e-02 -3.970e-02 -3.100e-03 -7.370e-02 -1.710e-02\n",
            "  -4.200e-03 -7.490e-02 -2.770e-02 -2.100e-03  9.900e-03 -8.330e-02\n",
            "  -4.380e-02 -5.260e-02 -3.680e-02 -1.072e-01 -1.206e-01 -1.848e-01\n",
            "   8.860e-02 -2.236e-01  6.790e-02 -4.710e-02 -1.245e-01 -2.930e-02\n",
            "  -3.060e-02 -5.500e-03  6.200e-03 -2.552e-01 -2.780e-02 -2.001e-01\n",
            "   6.900e-02  9.300e-03 -4.590e-02  6.000e-03 -1.884e-01 -7.500e-02]\n",
            " [ 4.030e-02 -1.070e-02  3.297e-01  3.410e-02  1.500e-02  1.123e-01\n",
            "  -8.740e-02 -1.290e-02  7.000e-03  6.010e-02  2.760e-02 -5.350e-02\n",
            "   7.580e-02  5.740e-02 -3.430e-02  1.307e-01  6.230e-02 -2.530e-02\n",
            "   8.570e-02  1.651e-01 -5.400e-02  1.710e-02 -9.790e-02  8.190e-02\n",
            "  -4.060e-02 -3.800e-02  6.270e-02  5.000e-03  1.103e-01  2.700e-02\n",
            "  -5.150e-02  4.320e-02  4.370e-02 -2.320e-02 -1.560e-02  3.250e-02\n",
            "   6.920e-02  8.310e-02  5.820e-02  1.152e-01  1.559e-01  2.917e-01\n",
            "  -1.400e-01  3.355e-01 -1.863e-01  2.390e-02  1.633e-01  4.640e-02\n",
            "   4.830e-02  8.700e-03 -9.800e-03  3.813e-01  4.390e-02  3.095e-01\n",
            "  -1.741e-01 -8.990e-02  7.250e-02 -9.400e-03  2.592e-01  5.040e-02]\n",
            " [-6.590e-02  1.760e-02 -5.374e-01 -5.160e-02 -2.460e-02 -1.838e-01\n",
            "   1.431e-01  2.120e-02 -1.140e-02 -7.740e-02 -4.510e-02  8.760e-02\n",
            "  -1.142e-01 -9.390e-02  7.120e-02 -2.139e-01 -1.020e-01  4.150e-02\n",
            "  -1.404e-01 -2.703e-01  8.840e-02 -2.800e-02  1.652e-01 -1.296e-01\n",
            "   6.650e-02  6.210e-02 -1.027e-01 -8.100e-03 -1.794e-01 -4.420e-02\n",
            "   9.500e-02 -5.680e-02 -7.160e-02  4.290e-02  2.560e-02 -3.490e-02\n",
            "  -1.133e-01 -1.360e-01 -9.530e-02 -1.786e-01 -2.487e-01 -4.775e-01\n",
            "   2.292e-01 -5.460e-01  3.196e-01 -2.980e-02 -2.611e-01 -7.590e-02\n",
            "  -7.910e-02 -1.420e-02  1.600e-02 -6.200e-01 -7.190e-02 -5.054e-01\n",
            "   2.971e-01  1.610e-01 -1.188e-01  1.540e-02 -4.172e-01 -7.000e-02]\n",
            " [-2.750e-02  7.300e-03 -2.236e-01 -2.080e-02 -1.020e-02 -7.660e-02\n",
            "   5.960e-02  8.800e-03 -4.700e-03 -2.900e-02 -1.880e-02  3.650e-02\n",
            "  -4.610e-02 -3.910e-02  3.200e-02 -8.910e-02 -4.250e-02  1.730e-02\n",
            "  -5.850e-02 -1.126e-01  3.680e-02 -1.170e-02  6.960e-02 -5.330e-02\n",
            "   2.770e-02  2.590e-02 -4.280e-02 -3.400e-03 -7.460e-02 -1.840e-02\n",
            "   4.130e-02 -2.150e-02 -2.980e-02  1.870e-02  1.070e-02 -1.170e-02\n",
            "  -4.720e-02 -5.670e-02 -3.970e-02 -7.290e-02 -1.026e-01 -1.990e-01\n",
            "   9.550e-02 -2.270e-01  1.355e-01 -1.100e-02 -1.079e-01 -3.160e-02\n",
            "  -3.290e-02 -5.900e-03  6.700e-03 -2.577e-01 -3.000e-02 -2.104e-01\n",
            "   1.257e-01  6.920e-02 -4.950e-02  6.400e-03 -1.727e-01 -2.720e-02]\n",
            " [ 6.520e-02 -1.740e-02  5.353e-01  5.860e-02  2.430e-02  1.817e-01\n",
            "  -1.414e-01 -2.090e-02  1.130e-02  1.144e-01  4.460e-02 -8.660e-02\n",
            "   1.307e-01  9.290e-02 -4.330e-02  2.115e-01  1.009e-01 -4.100e-02\n",
            "   1.387e-01  2.672e-01 -8.740e-02  2.770e-02 -1.545e-01  1.361e-01\n",
            "  -6.580e-02 -6.140e-02  1.015e-01  8.000e-03  1.794e-01  4.370e-02\n",
            "  -7.450e-02  8.130e-02  7.080e-02 -3.360e-02 -2.530e-02  6.760e-02\n",
            "   1.120e-01  1.344e-01  9.420e-02  1.947e-01  2.575e-01  4.722e-01\n",
            "  -2.266e-01  5.457e-01 -2.896e-01  4.630e-02  2.693e-01  7.510e-02\n",
            "   7.820e-02  1.410e-02 -1.580e-02  6.203e-01  7.110e-02  5.019e-01\n",
            "  -2.719e-01 -1.341e-01  1.174e-01 -1.530e-02  4.253e-01  9.190e-02]\n",
            " [-2.200e-03  6.000e-04 -2.050e-02 -5.800e-03 -8.000e-04 -6.300e-03\n",
            "   4.900e-03  7.000e-04 -4.000e-04 -2.280e-02 -1.500e-03  3.000e-03\n",
            "  -1.330e-02 -3.200e-03 -1.200e-02 -7.300e-03 -3.500e-03  1.400e-03\n",
            "  -4.800e-03 -9.200e-03  3.000e-03 -1.000e-03  1.000e-03 -8.700e-03\n",
            "   2.300e-03  2.100e-03 -3.500e-03 -3.000e-04 -7.200e-03 -1.500e-03\n",
            "  -7.100e-03 -1.530e-02 -2.400e-03 -3.200e-03  9.000e-04 -1.870e-02\n",
            "  -3.900e-03 -4.600e-03 -3.300e-03 -1.570e-02 -1.470e-02 -1.640e-02\n",
            "   7.800e-03 -2.180e-02 -3.100e-03 -1.000e-02 -1.480e-02 -2.600e-03\n",
            "  -2.700e-03 -5.000e-04  5.000e-04 -2.510e-02 -2.500e-03 -1.850e-02\n",
            "  -1.400e-03 -7.800e-03 -4.100e-03  5.000e-04 -2.110e-02 -1.450e-02]\n",
            " [-1.680e-02  4.500e-03 -1.421e-01 -2.320e-02 -6.300e-03 -4.680e-02\n",
            "   3.640e-02  5.400e-03 -2.900e-03 -6.970e-02 -1.150e-02  2.230e-02\n",
            "  -5.260e-02 -2.390e-02 -1.770e-02 -5.440e-02 -2.600e-02  1.060e-02\n",
            "  -3.570e-02 -6.880e-02  2.250e-02 -7.100e-03  3.050e-02 -4.360e-02\n",
            "   1.690e-02  1.580e-02 -2.610e-02 -2.100e-03 -4.840e-02 -1.120e-02\n",
            "  -1.400e-03 -4.760e-02 -1.820e-02 -7.000e-04  6.500e-03 -5.250e-02\n",
            "  -2.880e-02 -3.460e-02 -2.430e-02 -6.930e-02 -7.860e-02 -1.217e-01\n",
            "   5.830e-02 -1.468e-01  4.660e-02 -2.990e-02 -8.120e-02 -1.930e-02\n",
            "  -2.010e-02 -3.600e-03  4.100e-03 -1.676e-01 -1.830e-02 -1.316e-01\n",
            "   4.690e-02  7.900e-03 -3.020e-02  3.900e-03 -1.232e-01 -4.780e-02]\n",
            " [ 8.800e-03 -2.300e-03  7.470e-02  1.280e-02  3.300e-03  2.450e-02\n",
            "  -1.900e-02 -2.800e-03  1.500e-03  4.000e-02  6.000e-03 -1.170e-02\n",
            "   2.910e-02  1.250e-02  1.170e-02  2.850e-02  1.360e-02 -5.500e-03\n",
            "   1.870e-02  3.600e-02 -1.180e-02  3.700e-03 -1.510e-02  2.350e-02\n",
            "  -8.900e-03 -8.300e-03  1.370e-02  1.100e-03  2.550e-02  5.900e-03\n",
            "   2.500e-03  2.720e-02  9.500e-03  1.200e-03 -3.400e-03  3.050e-02\n",
            "   1.510e-02  1.810e-02  1.270e-02  3.790e-02  4.220e-02  6.370e-02\n",
            "  -3.050e-02  7.730e-02 -2.190e-02  1.720e-02  4.350e-02  1.010e-02\n",
            "   1.050e-02  1.900e-03 -2.100e-03  8.830e-02  9.600e-03  6.910e-02\n",
            "  -2.250e-02 -1.800e-03  1.580e-02 -2.100e-03  6.560e-02  2.710e-02]]\n",
            "[ 0.9171 -0.8259  0.1167 -0.5798  1.0222  0.4373 -0.8785 -0.0352  0.086\n",
            " -0.0327]\n",
            "[[-1.7470e-01  4.6600e-02 -1.4134e+00 ...  4.0900e-02 -1.0689e+00\n",
            "  -1.2000e-01]\n",
            " [-1.4140e-01  3.7700e-02 -1.1030e+00 ...  3.3100e-02 -7.3450e-01\n",
            "   1.3250e-01]\n",
            " [ 0.0000e+00  0.0000e+00  0.0000e+00 ...  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00]\n",
            " ...\n",
            " [-1.6950e-01  4.5200e-02 -1.3819e+00 ...  3.9700e-02 -1.0719e+00\n",
            "  -1.7810e-01]\n",
            " [ 0.0000e+00  0.0000e+00  0.0000e+00 ...  0.0000e+00  1.0000e-04\n",
            "   3.0000e-04]\n",
            " [-0.0000e+00 -0.0000e+00 -0.0000e+00 ... -0.0000e+00 -0.0000e+00\n",
            "  -0.0000e+00]]\n",
            "[ 3.0905e+00  3.8332e+00  1.0000e-04  4.0000e-04  3.2480e+00  2.7855e+00\n",
            "  4.3338e+00  2.3518e+00  2.6118e+00  1.5000e-03  1.5786e+00  1.1044e+00\n",
            "  2.0000e-04  4.0535e+00  1.2000e-03  1.5891e+00  4.5093e+00  1.1215e+00\n",
            "  5.2431e+00  1.1990e+00  6.8670e-01  2.6003e+00  6.0000e-04  6.0000e-04\n",
            "  5.6354e+00  2.1163e+00  9.8380e-01  6.7670e-01 -2.3000e-03  1.9696e+00\n",
            " -3.0000e-04 -1.0000e-04  4.2536e+00 -4.0000e-04  3.3284e+00 -1.9000e-03\n",
            "  5.7310e-01  3.7580e-01  3.0150e+00 -3.0000e-04 -1.0000e-04  7.0000e-04\n",
            "  4.0374e+00  3.1000e-03 -1.3000e-03 -3.0000e-04  1.1000e-03  1.8777e+00\n",
            "  9.7770e-01  4.8665e+00  2.7545e+00  2.4000e-03  3.9700e-02  2.4000e-03\n",
            "  1.0000e-04  0.0000e+00  1.3012e+00  2.6400e+00  1.5000e-03 -0.0000e+00]\n",
            "-11.036180678360868\n",
            "0.5011429610180692\n",
            "4.534603540063673\n",
            "0.5963327065594722\n",
            "251.67021146376376\n",
            "-6.768933891624769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3CWd7zSVIEt"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}